import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader
from PIL import Image
import os
import numpy as np
from torchvision.models import resnet50
import cv2
from sklearn.preprocessing import LabelEncoder

# Reuse the provided model architectures
class ResidualBlock(nn.Module):
    def __init__(self, channels):
        super(ResidualBlock, self).__init__()
        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)
        self.relu = nn.ReLU(inplace=True)
        
    def forward(self, x):
        residual = x
        x = self.conv1(x)
        x = self.relu(x)
        x = self.conv2(x)
        x += residual
        x = self.relu(x)
        return x

class FaceEncoder(nn.Module):
    def __init__(self, input_channels=3, embedding_dim=128):
        super(FaceEncoder, self).__init__()
        self.conv1 = nn.Conv2d(input_channels, 64, kernel_size=7, stride=2, padding=3)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
        self.res1 = ResidualBlock(64)
        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)
        self.res2 = ResidualBlock(128)
        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1)
        self.res3 = ResidualBlock(256)
        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1)
        self.res4 = ResidualBlock(512)
        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = nn.Linear(512, embedding_dim)
        
    def forward(self, x):
        x = self.conv1(x)
        x = F.relu(x)
        x = self.pool(x)
        x = self.res1(x)
        x = self.conv2(x)
        x = F.relu(x)
        x = self.res2(x)
        x = self.conv3(x)
        x = F.relu(x)
        x = self.res3(x)
        x = self.conv4(x)
        x = F.relu(x)
        x = self.res4(x)
        x = self.global_pool(x)
        x = torch.flatten(x, 1)
        x = self.fc(x)
        return F.normalize(x, p=2, dim=1)  # L2 normalize embeddings

class FaceDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.root_dir = root_dir
        self.transform = transform
        self.classes = os.listdir(root_dir)
        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}
        self.samples = []
        
        for class_name in self.classes:
            class_dir = os.path.join(root_dir, class_name)
            if os.path.isdir(class_dir):
                for img_name in os.listdir(class_dir):
                    if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):
                        self.samples.append((os.path.join(class_dir, img_name), self.class_to_idx[class_name]))
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        img_path, label = self.samples[idx]
        image = Image.open(img_path).convert('RGB')
        
        if self.transform:
            image = self.transform(image)
            
        return image, label

class FaceRecognitionSystem:
    def __init__(self, data_dir, model_save_path='face_recognition_model.pth'):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model = FaceEncoder().to(self.device)
        self.model_save_path = model_save_path
        self.data_dir = data_dir
        
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        
        # Initialize label encoder
        self.label_encoder = LabelEncoder()
        self.label_encoder.fit(os.listdir(data_dir))
        
    def train(self, epochs=10, batch_size=32, learning_rate=0.001):
        dataset = FaceDataset(self.data_dir, transform=self.transform)
        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)
        
        criterion = nn.CrossEntropyLoss()
        optimizer = torch.optim.Adam(self.model.parameters(), lr=learning_rate)
        
        self.model.train()
        for epoch in range(epochs):
            running_loss = 0.0
            for images, labels in dataloader:
                images, labels = images.to(self.device), labels.to(self.device)
                
                optimizer.zero_grad()
                embeddings = self.model(images)
                
                # Simple classification loss for training
                loss = criterion(embeddings, labels)
                loss.backward()
                optimizer.step()
                
                running_loss += loss.item()
            
            print(f'Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(dataloader):.4f}')
        
        torch.save(self.model.state_dict(), self.model_save_path)
        print(f"Model saved to {self.model_save_path}")
    
    def load_model(self):
        self.model.load_state_dict(torch.load(self.model_save_path))
        self.model.eval()
    
    def preprocess_image(self, image_path):
        image = Image.open(image_path).convert('RGB')
        return self.transform(image).unsqueeze(0).to(self.device)
    
    def identify(self, image_path, threshold=0.6):
        self.model.eval()
        with torch.no_grad():
            # Preprocess and get embedding for the input image
            image = self.preprocess_image(image_path)
            embedding = self.model(image)
            
            # Compare with all known faces
            best_match = None
            best_similarity = -1
            
            for class_name in os.listdir(self.data_dir):
                class_dir = os.path.join(self.data_dir, class_name)
                if os.path.isdir(class_dir):
                    # Get first image from the class directory for comparison
                    for img_name in os.listdir(class_dir):
                        if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):
                            reference_path = os.path.join(class_dir, img_name)
                            reference_image = self.preprocess_image(reference_path)
                            reference_embedding = self.model(reference_image)
                            
                            # Calculate cosine similarity
                            similarity = F.cosine_similarity(embedding, reference_embedding).item()
                            
                            if similarity > best_similarity:
                                best_similarity = similarity
                                best_match = class_name
                            break
            
            if best_similarity > threshold:
                return best_match, best_similarity
            else:
                return "Unknown", best_similarity

# Example usage
def main():
    # Initialize the system
    face_system = FaceRecognitionSystem(data_dir='path/to/training/data')
    
    # Train the model (uncomment to train)
    # face_system.train(epochs=10)
    
    # Load a pre-trained model
    face_system.load_model()
    
    # Identify a person from an image
    image_path = 'path/to/test/image.jpg'
    person, confidence = face_system.identify(image_path)
    print(f"Identified person: {person}")
    print(f"Confidence: {confidence:.2f}")

if __name__ == "__main__":
    main()
